<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/LLMAttackSim/_next/static/css/accb739d9c136990.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/LLMAttackSim/_next/static/chunks/webpack-a5027223ad964231.js"/><script src="/LLMAttackSim/_next/static/chunks/4bd1b696-3abbb802821b0a68.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/684-2e4a38493551f6d1.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/main-app-341792834c8fe45b.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/874-476808868ec6108b.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/671-992ed7dc896d40b8.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/app/layout-1b6a77419984f623.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/455-776491f79aee79eb.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/489-53b97e6b4470e9e1.js" async=""></script><script src="/LLMAttackSim/_next/static/chunks/app/education/guides/safety-mechanisms/page-8b54b5ccf3d9ffff.js" async=""></script><title>LLM Safety Simulator - Educational Platform</title><meta name="description" content="An educational platform designed to demonstrate LLM vulnerabilities and promote the importance of robust safety measures in AI systems."/><link rel="icon" href="/LLMAttackSim/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/LLMAttackSim/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_61751f"><script>((e,t,r,n,a,o,i,l)=>{let u=document.documentElement,s=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&o?a.map(e=>o[e]||e):a;r?(u.classList.remove(...n),u.classList.add(o&&o[t]?o[t]:t)):u.setAttribute(e,t)}),r=t,l&&s.includes(r)&&(u.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","system",null,["light","dark"],null,true,true)</script><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section><div class="flex min-h-screen flex-col"><header class="sticky top-0 z-50 w-full border-b bg-background/95 backdrop-blur-sm supports-[backdrop-filter]:bg-background/60"><div class="container flex h-16 items-center space-x-4 sm:justify-between sm:space-x-0"><div class="flex gap-2 items-center text-primary"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-shield h-6 w-6"><path d="M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"></path></svg><span class="font-bold text-lg">LLM Safety Simulator</span></div><div class="flex flex-1 items-center justify-end space-x-4"><a class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-hidden focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 h-8 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5 flex items-center gap-1" data-slot="button" href="/LLMAttackSim/education"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left h-4 w-4"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg> <!-- -->Back to Education</a><button data-slot="dropdown-menu-trigger" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-hidden focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 size-9" type="button" id="radix-«Rkjrndlb»" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun h-[1.2rem] w-[1.2rem] rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-moon absolute h-[1.2rem] w-[1.2rem] rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path></svg><span class="sr-only">Toggle theme</span></button></div></div></header><main class="flex-1 container py-10"><div class="flex flex-col gap-6 max-w-4xl mx-auto"><div><h1 class="text-3xl font-bold tracking-tight">Safety Mechanisms Explained</h1><p class="text-muted-foreground mt-2">A detailed look at the various safety mechanisms implemented in modern LLMs</p></div><div class="bg-yellow-50 border border-yellow-200 text-yellow-800 rounded-md p-4 flex items-start gap-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-triangle-alert h-5 w-5 mt-0.5 shrink-0"><path d="m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3"></path><path d="M12 9v4"></path><path d="M12 17h.01"></path></svg><div><h3 class="font-medium">Educational Purpose Notice</h3><p class="text-sm mt-1">This material aims to increase transparency around AI safety features. It is not intended to reveal or exploit vulnerabilities.</p></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-xs"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-[data-slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6"><div data-slot="card-title" class="leading-none font-semibold">Overview</div><div data-slot="card-description" class="text-muted-foreground text-sm">What safety mechanisms are and why they matter</div></div><div data-slot="card-content" class="px-6 space-y-4"><p class="text-sm text-muted-foreground">Large language models are equipped with various safety systems designed to prevent harmful, misleading, or unethical outputs. These mechanisms are essential to reduce risks, build trust, and guide responsible AI deployment.</p></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-xs"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-[data-slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6"><div data-slot="card-title" class="leading-none font-semibold">Types of Safety Mechanisms</div><div data-slot="card-description" class="text-muted-foreground text-sm">Common methods used to protect users and outputs</div></div><div data-slot="card-content" class="px-6"><div class="grid gap-4"><div class="bg-muted p-4 rounded-lg"><h3 class="font-medium mb-1">Content Filtering</h3><p class="text-sm text-muted-foreground">Blocking or flagging outputs that contain unsafe or inappropriate material.</p></div><div class="bg-muted p-4 rounded-lg"><h3 class="font-medium mb-1">Instruction Tuning</h3><p class="text-sm text-muted-foreground">Training the model on helpful, harmless, and honest behaviors through carefully curated data.</p></div><div class="bg-muted p-4 rounded-lg"><h3 class="font-medium mb-1">Reinforcement Learning from Human Feedback (RLHF)</h3><p class="text-sm text-muted-foreground">Aligning model responses with human values using feedback from real users and evaluators.</p></div><div class="bg-muted p-4 rounded-lg"><h3 class="font-medium mb-1">System-Level Guards</h3><p class="text-sm text-muted-foreground">External rules or constraints imposed by the application hosting the model, such as API filters.</p></div></div></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-xs"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-[data-slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6"><div data-slot="card-title" class="leading-none font-semibold">Challenges and Limitations</div><div data-slot="card-description" class="text-muted-foreground text-sm">Understanding current safety trade-offs</div></div><div data-slot="card-content" class="px-6"><div class="grid gap-4"><div class="bg-muted p-4 rounded-lg"><h3 class="font-medium mb-1">Overblocking</h3><p class="text-sm text-muted-foreground">Safety filters may block legitimate and harmless content, limiting usability.</p></div><div class="bg-muted p-4 rounded-lg"><h3 class="font-medium mb-1">False Negatives</h3><p class="text-sm text-muted-foreground">Not all unsafe content is detected, especially in nuanced or adversarial prompts.</p></div><div class="bg-muted p-4 rounded-lg"><h3 class="font-medium mb-1">Context Sensitivity</h3><p class="text-sm text-muted-foreground">Safety mechanisms may struggle to understand intent or context in long, multi-turn exchanges.</p></div></div></div></div></div></main><footer class="w-full border-t py-6 md:py-0"><div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row"><p class="text-center text-sm leading-loose text-muted-foreground md:text-left">© <!-- -->2025<!-- --> LLM Safety Simulator. All rights reserved.</p><div class="flex items-center gap-4 text-sm text-muted-foreground"><a class="hover:underline underline-offset-4" href="/LLMAttackSim/terms">Terms</a><a class="hover:underline underline-offset-4" href="/LLMAttackSim/privacy">Privacy</a><a class="hover:underline underline-offset-4" href="/LLMAttackSim/contact">Contact</a></div></div></footer></div><script src="/LLMAttackSim/_next/static/chunks/webpack-a5027223ad964231.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9304,[\"874\",\"static/chunks/874-476808868ec6108b.js\",\"671\",\"static/chunks/671-992ed7dc896d40b8.js\",\"177\",\"static/chunks/app/layout-1b6a77419984f623.js\"],\"ThemeProvider\"]\n3:I[6671,[\"874\",\"static/chunks/874-476808868ec6108b.js\",\"671\",\"static/chunks/671-992ed7dc896d40b8.js\",\"177\",\"static/chunks/app/layout-1b6a77419984f623.js\"],\"Toaster\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n6:I[6874,[\"874\",\"static/chunks/874-476808868ec6108b.js\",\"455\",\"static/chunks/455-776491f79aee79eb.js\",\"489\",\"static/chunks/489-53b97e6b4470e9e1.js\",\"777\",\"static/chunks/app/education/guides/safety-mechanisms/page-8b54b5ccf3d9ffff.js\"],\"\"]\n7:I[6550,[\"874\",\"static/chunks/874-476808868ec6108b.js\",\"455\",\"static/chunks/455-776491f79aee79eb.js\",\"489\",\"static/chunks/489-53b97e6b4470e9e1.js\",\"777\",\"static/chunks/app/education/guides/safety-mechanisms/page-8b54b5ccf3d9ffff.js\"],\"default\"]\n8:I[9665,[],\"OutletBoundary\"]\nb:I[9665,[],\"ViewportBoundary\"]\nd:I[9665,[],\"MetadataBoundary\"]\nf:I[6614,[],\"\"]\n:HL[\"/LLMAttackSim/_next/static/css/accb739d9c136990.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"cMenYe2BQQY8bHatVSEjr\",\"p\":\"/LLMAttackSim\",\"c\":[\"\",\"education\",\"guides\",\"safety-mechanisms\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"education\",{\"children\":[\"guides\",{\"children\":[\"safety-mechanisms\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/LLMAttackSim/_next/static/css/accb739d9c136990.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"__className_61751f\",\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"system\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[[\"$\",\"$L3\",null,{}],[\"$\",\"div\",null,{\"className\":\"flex min-h-screen flex-col\",\"children\":[[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"className\":\"w-full border-t py-6 md:py-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-center text-sm leading-loose text-muted-foreground md:text-left\",\"children\":[\"© \",2025,\" LLM Safety Simulator. All rights reserved.\"]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"/terms\",\"className\":\"hover:underline underline-offset-4\",\"children\":\"Terms\"}],[\"$\",\"$L6\",null,{\"href\":\"/privacy\",\"className\":\"hover:underline underline-offset-4\",\"children\":\"Privacy\"}],[\"$\",\"$L6\",null,{\"href\":\"/contact\",\"className\":\"hover:underline underline-offset-4\",\"children\":\"Contact\"}]]}]]}]}]]}]]}]}]}]]}],{\"children\":[\"education\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"guides\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"safety-mechanisms\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"header\",null,{\"className\":\"sticky top-0 z-50 w-full border-b bg-background/95 backdrop-blur-sm supports-[backdrop-filter]:bg-background/60\",\"children\":[\"$\",\"div\",null,{\"className\":\"container flex h-16 items-center space-x-4 sm:justify-between sm:space-x-0\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex gap-2 items-center text-primary\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-shield h-6 w-6\",\"children\":[[\"$\",\"path\",\"oel41y\",{\"d\":\"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"font-bold text-lg\",\"children\":\"LLM Safety Simulator\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-1 items-center justify-end space-x-4\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"/education\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-hidden focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 h-8 rounded-md gap-1.5 px-3 has-[\u003esvg]:px-2.5 flex items-center gap-1\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left h-4 w-4\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],\" \",\"Back to Education\"],\"data-slot\":\"button\",\"ref\":null}],[\"$\",\"$L7\",null,{}]]}]]}]}],[\"$\",\"main\",null,{\"className\":\"flex-1 container py-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-6 max-w-4xl mx-auto\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-3xl font-bold tracking-tight\",\"children\":\"Safety Mechanisms Explained\"}],[\"$\",\"p\",null,{\"className\":\"text-muted-foreground mt-2\",\"children\":\"A detailed look at the various safety mechanisms implemented in modern LLMs\"}]]}],[\"$\",\"div\",null,{\"className\":\"bg-yellow-50 border border-yellow-200 text-yellow-800 rounded-md p-4 flex items-start gap-3\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-triangle-alert h-5 w-5 mt-0.5 shrink-0\",\"children\":[[\"$\",\"path\",\"wmoenq\",{\"d\":\"m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3\"}],[\"$\",\"path\",\"juzpu7\",{\"d\":\"M12 9v4\"}],[\"$\",\"path\",\"p32p05\",{\"d\":\"M12 17h.01\"}],\"$undefined\"]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium\",\"children\":\"Educational Purpose Notice\"}],[\"$\",\"p\",null,{\"className\":\"text-sm mt-1\",\"children\":\"This material aims to increase transparency around AI safety features. It is not intended to reveal or exploit vulnerabilities.\"}]]}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-xs\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card-header\",\"className\":\"@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-[data-slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card-title\",\"className\":\"leading-none font-semibold\",\"children\":\"Overview\"}],[\"$\",\"div\",null,{\"data-slot\":\"card-description\",\"className\":\"text-muted-foreground text-sm\",\"children\":\"What safety mechanisms are and why they matter\"}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"px-6 space-y-4\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Large language models are equipped with various safety systems designed to prevent harmful, misleading, or unethical outputs. These mechanisms are essential to reduce risks, build trust, and guide responsible AI deployment.\"}]}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-xs\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card-header\",\"className\":\"@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-[data-slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card-title\",\"className\":\"leading-none font-semibold\",\"children\":\"Types of Safety Mechanisms\"}],[\"$\",\"div\",null,{\"data-slot\":\"card-description\",\"className\":\"text-muted-foreground text-sm\",\"children\":\"Common methods used to protect users and outputs\"}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"px-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid gap-4\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-muted p-4 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium mb-1\",\"children\":\"Content Filtering\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Blocking or flagging outputs that contain unsafe or inappropriate material.\"}]]}],[\"$\",\"div\",\"1\",{\"className\":\"bg-muted p-4 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium mb-1\",\"children\":\"Instruction Tuning\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Training the model on helpful, harmless, and honest behaviors through carefully curated data.\"}]]}],[\"$\",\"div\",\"2\",{\"className\":\"bg-muted p-4 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium mb-1\",\"children\":\"Reinforcement Learning from Human Feedback (RLHF)\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Aligning model responses with human values using feedback from real users and evaluators.\"}]]}],[\"$\",\"div\",\"3\",{\"className\":\"bg-muted p-4 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium mb-1\",\"children\":\"System-Level Guards\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"External rules or constraints imposed by the application hosting the model, such as API filters.\"}]]}]]}]}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-xs\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card-header\",\"className\":\"@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-[data-slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card-title\",\"className\":\"leading-none font-semibold\",\"children\":\"Challenges and Limitations\"}],[\"$\",\"div\",null,{\"data-slot\":\"card-description\",\"className\":\"text-muted-foreground text-sm\",\"children\":\"Understanding current safety trade-offs\"}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"px-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid gap-4\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-muted p-4 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium mb-1\",\"children\":\"Overblocking\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Safety filters may block legitimate and harmless content, limiting usability.\"}]]}],[\"$\",\"div\",\"1\",{\"className\":\"bg-muted p-4 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium mb-1\",\"children\":\"False Negatives\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Not all unsafe content is detected, especially in nuanced or adversarial prompts.\"}]]}],[\"$\",\"div\",\"2\",{\"className\":\"bg-muted p-4 rounded-lg\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-medium mb-1\",\"children\":\"Context Sensitivity\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Safety mechanisms may struggle to understand intent or context in long, multi-turn exchanges.\"}]]}]]}]}]]}]]}]}]],\"$undefined\",null,[\"$\",\"$L8\",null,{\"children\":[\"$L9\",\"$La\",null]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"DD_iZ6ZZpRo8lx7lTROsU\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],null]}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:null\n"])</script><script>self.__next_f.push([1,"a:null\ne:[[\"$\",\"title\",\"0\",{\"children\":\"LLM Safety Simulator - Educational Platform\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"An educational platform designed to demonstrate LLM vulnerabilities and promote the importance of robust safety measures in AI systems.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/LLMAttackSim/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script></body></html>